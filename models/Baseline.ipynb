{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNjO3D1zl5iH",
        "outputId": "f48a5f39-15ae-44ed-af2f-86bcd284e916"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Google colab version\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9kSro4HgmAIH"
      },
      "outputs": [],
      "source": [
        "# Load df Google Colab (feature engineered, encoded, scaled/unscaled)\n",
        "import pandas as pd\n",
        "df_sampled_unscaled = pd.read_csv(\"/content/drive/My Drive/Thesis/Data/df_sampled_unscaled.csv\")\n",
        "df_sampled_scaled = pd.read_csv(\"/content/drive/My Drive/Thesis/Data/df_sampled_scaled.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df_final = pd.read_csv(\"/content/drive/My Drive/Thesis/Data/df_final_2.csv\")"
      ],
      "metadata": {
        "id": "uxsZp16WHOH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Random Forest baseline nog runnen 15/11**"
      ],
      "metadata": {
        "id": "eR7eYoVFBWlY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import joblib\n",
        "from google.colab import drive\n",
        "from sklearn.model_selection import KFold, train_test_split, RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
      ],
      "metadata": {
        "id": "BumORLoNBrKB"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load df Google Colab\n",
        "drive.mount('/content/drive')\n",
        "df_final = pd.read_csv(\"/content/drive/My Drive/Thesis/Data/df_final_2.csv\")\n",
        "\n",
        "df_final = df_final.astype(np.int32)"
      ],
      "metadata": {
        "id": "N2MCXRJIBnT-",
        "outputId": "89667536-4f40-46e6-f07c-19311e7629ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define feature and target\n",
        "X = df_final.drop(columns=['Rating'])\n",
        "y = df_final['Rating']\n",
        "\n",
        "# Split data 80% train, 20% test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
        "                                                    stratify=y, random_state=42)\n",
        "\n",
        "# Define the parameter grid for hyperparameter optimization\n",
        "param_dist = {\n",
        "    'n_estimators': [100, 200, 250, 300],\n",
        "    'max_depth': [20, 30, 40, 50],\n",
        "    'min_samples_split': [2,5,10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Define the inner and outer cross-validation strategies\n",
        "inner_cv = KFold(n_splits=3, shuffle=True, random_state=42)\n",
        "outer_cv = KFold(n_splits=5, shuffle=True, random_state=42)\n"
      ],
      "metadata": {
        "id": "WGlPkz5LB17i"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the Randomized Search\n",
        "random_search = RandomizedSearchCV(estimator=RandomForestClassifier(),\n",
        "                                   param_distributions=param_dist, n_iter=15,\n",
        "                                   cv=inner_cv, scoring='accuracy')\n",
        "\n",
        "# Define output lists\n",
        "outer_scores = []\n",
        "val_scores = []\n",
        "best_params_list = []\n",
        "\n",
        "# Perform nested CV\n",
        "for train_idx, val_idx in outer_cv.split(X_train, y_train):\n",
        "    # Split the data into training and validation sets\n",
        "    X_train_fold = X_train.iloc[train_idx]\n",
        "    X_val_fold = X_train.iloc[val_idx]\n",
        "    y_train_fold = y_train.iloc[train_idx]\n",
        "    y_val_fold = y_train.iloc[val_idx]\n",
        "\n",
        "    # Fit the model on the training fold\n",
        "    random_search.fit(X_train_fold, y_train_fold)\n",
        "    best_model = random_search.best_estimator_\n",
        "\n",
        "    # Save the best parameters for this fold\n",
        "    best_params_list.append(random_search.best_params_)\n",
        "\n",
        "    # Evaluate on the validation set\n",
        "    val_predictions = best_model.predict(X_val_fold)\n",
        "    val_acc = accuracy_score(y_val_fold, val_predictions)\n",
        "    val_prec = precision_score(y_val_fold, val_predictions, average='weighted')\n",
        "    val_rec = recall_score(y_val_fold, val_predictions, average='weighted')\n",
        "    val_f1 = f1_score(y_val_fold, val_predictions, average='weighted')\n",
        "\n",
        "    # Store validation metrics\n",
        "    val_scores.append((val_acc, val_prec, val_rec, val_f1))\n",
        "\n",
        "    # Store the outer fold score (accuracy)\n",
        "    outer_scores.append(random_search.best_score_)\n",
        "\n",
        "# Print the performance of the nested CV\n",
        "print(f\"Nested Cross-Validation Accuracy: {np.mean(outer_scores):.2f} ± {np.std(outer_scores):.2f}\")\n",
        "\n",
        "# Print validation set performance for each fold\n",
        "val_scores = np.array(val_scores)\n",
        "print(\"Validation Set Performance:\")\n",
        "print(f\"Accuracy: {val_scores[:, 0].mean():.2f} ± {val_scores[:, 0].std():.2f}\")\n",
        "print(f\"Precision: {val_scores[:, 1].mean():.2f} ± {val_scores[:, 1].std():.2f}\")\n",
        "print(f\"Recall: {val_scores[:, 2].mean():.2f} ± {val_scores[:, 2].std():.2f}\")\n",
        "print(f\"F1 Score: {val_scores[:, 3].mean():.2f} ± {val_scores[:, 3].std():.2f}\")\n",
        "\n",
        "# Print the best parameters found during hyperparameter tuning\n",
        "print(\"Best parameters found during hyperparameter tuning:\")\n",
        "for i, params in enumerate(best_params_list):\n",
        "    print(f\"Fold {i+1}: {params}\")\n",
        "\n",
        "# Define the best parameters found in nested CV\n",
        "best_params = best_params_list[np.argmax(outer_scores)]\n",
        "\n",
        "# Train the best model\n",
        "best_model = RandomForestClassifier(**best_params, random_state=42)\n",
        "best_model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate on the test set\n",
        "test_predictions = best_model.predict(X_test)\n",
        "print(\"Test set performance for best performing model:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, test_predictions):.2f}\")\n",
        "print(f\"Precision: {precision_score(y_test, test_predictions, average='weighted'):.2f}\")\n",
        "print(f\"Recall: {recall_score(y_test, test_predictions, average='weighted'):.2f}\")\n",
        "print(f\"F1 Score: {f1_score(y_test, test_predictions, average='weighted'):.2f}\")\n",
        "\n",
        "# Print the parameters for the best-performing model\n",
        "print(\"Parameters for the best performing model:\")\n",
        "print(best_params)\n",
        "\n",
        "# Save the best performing model\n",
        "joblib_file = \"/content/drive/My Drive/Thesis/Models/Baseline_RF.pkl\"\n",
        "joblib.dump(best_model, joblib_file)\n"
      ],
      "metadata": {
        "id": "_sVX3bf2CIDE",
        "outputId": "faed2314-91b5-42b3-e55f-b1e16346e98e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/ma/core.py:2820: RuntimeWarning: invalid value encountered in cast\n",
            "  _data = np.array(data, dtype=dtype, copy=copy,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nested Cross-Validation Accuracy: 0.41 ± 0.00\n",
            "Validation Set Performance:\n",
            "Accuracy: 0.42 ± 0.00\n",
            "Precision: 0.42 ± 0.00\n",
            "Recall: 0.42 ± 0.00\n",
            "F1 Score: 0.39 ± 0.00\n",
            "Best parameters found during hyperparameter tuning:\n",
            "Fold 1: {'n_estimators': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_depth': 30}\n",
            "Fold 2: {'n_estimators': 250, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_depth': 40}\n",
            "Fold 3: {'n_estimators': 300, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_depth': 40}\n",
            "Fold 4: {'n_estimators': 250, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_depth': 40}\n",
            "Fold 5: {'n_estimators': 300, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_depth': 40}\n",
            "Test set performance for best performing model:\n",
            "Accuracy: 0.42\n",
            "Precision: 0.43\n",
            "Recall: 0.42\n",
            "F1 Score: 0.40\n",
            "Parameters for the best performing model:\n",
            "{'n_estimators': 300, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_depth': 40}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/My Drive/Thesis/Models/Baseline_RF.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **XGBoost baseline 16/11**"
      ],
      "metadata": {
        "id": "QDKqZQqSwkPQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install xgboost"
      ],
      "metadata": {
        "id": "Z61n3CeTwnFp",
        "outputId": "22ee0f30-e079-4539-a33f-aafd78fe39c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (2.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.26.4)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.10/dist-packages (from xgboost) (2.23.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.13.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "import joblib\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from google.colab import drive\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import make_scorer, f1_score\n",
        "from sklearn.model_selection import KFold, RandomizedSearchCV, StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, make_scorer"
      ],
      "metadata": {
        "id": "zc5O8afiwrJy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load in the data\n",
        "drive.mount('/content/drive')\n",
        "df_final = pd.read_csv('/content/drive/My Drive/Thesis/Data/df_final_2.csv')\n",
        "\n",
        "df_final = df_final.astype(np.int32)"
      ],
      "metadata": {
        "id": "Aia4WYx_wtHL",
        "outputId": "4cb3e4d1-9cbd-428b-830c-b03fb8fdb404",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Fit and transform the \"Rating\" column\n",
        "df_final['Rating'] = label_encoder.fit_transform(df_final['Rating'])"
      ],
      "metadata": {
        "id": "0ZRqPQkjw0oE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define feature and target\n",
        "X = df_final.drop(columns=['Rating'])\n",
        "y = df_final['Rating']\n",
        "\n",
        "# Split data 80% train, 20% test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
        "                                                    stratify=y, random_state=42)\n",
        "\n",
        "# Define the parameter grid for tuning\n",
        "param_dist = {\n",
        "    'n_estimators': [100, 200, 300, 400],\n",
        "    'learning_rate': [0.05, 0.1, 0.2],\n",
        "    'max_depth': [3, 5, 7],\n",
        "}\n",
        "\n",
        "# Define the inner and outer cross-validation strategies\n",
        "inner_cv = KFold(n_splits=3, shuffle=True, random_state=42)\n",
        "outer_cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Define the scoring metric\n",
        "f1_weighted_scorer = make_scorer(f1_score, average='weighted')"
      ],
      "metadata": {
        "id": "deNv3Xqzw49H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the RandomizedSearchCV\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=XGBClassifier(tree_method='hist', device='cuda',\n",
        "                            eval_metric='merror'),\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=15,\n",
        "    cv=inner_cv,\n",
        "    scoring=f1_weighted_scorer,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Define output lists\n",
        "outer_scores = []\n",
        "val_scores = []\n",
        "best_params_list = []\n",
        "\n",
        "# Perform nested CV on the training data\n",
        "for train_idx, val_idx in outer_cv.split(X_train, y_train):\n",
        "    # Split the data into training and validation sets\n",
        "    X_train_fold = X_train.iloc[train_idx]\n",
        "    X_val_fold = X_train.iloc[val_idx]\n",
        "    y_train_fold = y_train.iloc[train_idx]\n",
        "    y_val_fold = y_train.iloc[val_idx]\n",
        "\n",
        "    # Fit the model on the training fold\n",
        "    random_search.fit(X_train_fold, y_train_fold)\n",
        "    best_model = random_search.best_estimator_\n",
        "\n",
        "    # Save the best parameters for this fold\n",
        "    best_params_list.append(random_search.best_params_)\n",
        "\n",
        "    # Evaluate on the validation set\n",
        "    val_predictions = best_model.predict(X_val_fold)\n",
        "    val_acc = accuracy_score(y_val_fold, val_predictions)\n",
        "    val_prec = precision_score(y_val_fold, val_predictions, average='weighted')\n",
        "    val_rec = recall_score(y_val_fold, val_predictions, average='weighted')\n",
        "    val_f1 = f1_score(y_val_fold, val_predictions, average='weighted')\n",
        "\n",
        "    # Store validation metrics\n",
        "    val_scores.append((val_acc, val_prec, val_rec, val_f1))\n",
        "\n",
        "    # Store the outer fold score (f1_weighted)\n",
        "    outer_scores.append(random_search.best_score_)\n",
        "\n",
        "# Print the performance of the nested CV\n",
        "print(f\"Nested Cross-Validation F1 Score: {np.mean(outer_scores):.2f} ± {np.std(outer_scores):.2f}\")\n",
        "\n",
        "# Print validation set performance for each fold\n",
        "val_scores = np.array(val_scores)\n",
        "print(\"Validation Set Performance:\")\n",
        "print(f\"Accuracy: {val_scores[:, 0].mean():.2f} ± {val_scores[:, 0].std():.2f}\")\n",
        "print(f\"Precision: {val_scores[:, 1].mean():.2f} ± {val_scores[:, 1].std():.2f}\")\n",
        "print(f\"Recall: {val_scores[:, 2].mean():.2f} ± {val_scores[:, 2].std():.2f}\")\n",
        "print(f\"F1 Score: {val_scores[:, 3].mean():.2f} ± {val_scores[:, 3].std():.2f}\")\n",
        "\n",
        "# Print the best parameters found during hyperparameter tuning\n",
        "print(\"Best parameters found during hyperparameter tuning:\")\n",
        "for i, params in enumerate(best_params_list):\n",
        "    print(f\"Fold {i+1}: {params}\")\n",
        "\n",
        "# Define the best parameters found in nested CV\n",
        "best_params = best_params_list[np.argmax(outer_scores)]\n",
        "\n",
        "# Train best model on the entire training data\n",
        "best_model = XGBClassifier(**best_params, tree_method='hist',\n",
        "                           device='cuda', eval_metric='merror',\n",
        "                           random_state=42)\n",
        "best_model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate on the test set\n",
        "test_predictions = best_model.predict(X_test)\n",
        "print(\"Test set performance for best performing model:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, test_predictions):.2f}\")\n",
        "print(f\"Precision: {precision_score(y_test, test_predictions, average='weighted'):.2f}\")\n",
        "print(f\"Recall: {recall_score(y_test, test_predictions, average='weighted'):.2f}\")\n",
        "print(f\"F1 Score: {f1_score(y_test, test_predictions, average='weighted'):.2f}\")\n",
        "\n",
        "# Print the parameters for the best-performing model\n",
        "print(\"Parameters for the best performing model:\")\n",
        "print(best_params)\n",
        "\n",
        "# Save the best performing model\n",
        "joblib_file = \"/content/drive/My Drive/Thesis/Models/Baseline_XGB.pkl\"\n",
        "joblib.dump(best_model, joblib_file)\n"
      ],
      "metadata": {
        "id": "R9X8MN1Aw7P-",
        "outputId": "57987401-9d19-4846-ae34-b415b6aa77ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/ma/core.py:2820: RuntimeWarning: invalid value encountered in cast\n",
            "  _data = np.array(data, dtype=dtype, copy=copy,\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [11:46:48] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
            "Potential solutions:\n",
            "- Use a data structure that matches the device ordinal in the booster.\n",
            "- Set the device for booster before call to inplace_predict.\n",
            "\n",
            "This warning will only be shown once.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nested Cross-Validation F1 Score: 0.41 ± 0.00\n",
            "Validation Set Performance:\n",
            "Accuracy: 0.44 ± 0.00\n",
            "Precision: 0.43 ± 0.00\n",
            "Recall: 0.44 ± 0.00\n",
            "F1 Score: 0.42 ± 0.00\n",
            "Best parameters found during hyperparameter tuning:\n",
            "Fold 1: {'n_estimators': 400, 'max_depth': 7, 'learning_rate': 0.2}\n",
            "Fold 2: {'n_estimators': 400, 'max_depth': 7, 'learning_rate': 0.1}\n",
            "Fold 3: {'n_estimators': 300, 'max_depth': 7, 'learning_rate': 0.2}\n",
            "Fold 4: {'n_estimators': 400, 'max_depth': 7, 'learning_rate': 0.1}\n",
            "Fold 5: {'n_estimators': 400, 'max_depth': 7, 'learning_rate': 0.2}\n",
            "Test set performance for best performing model:\n",
            "Accuracy: 0.44\n",
            "Precision: 0.44\n",
            "Recall: 0.44\n",
            "F1 Score: 0.43\n",
            "Parameters for the best performing model:\n",
            "{'n_estimators': 400, 'max_depth': 7, 'learning_rate': 0.2}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/My Drive/Thesis/Models/Baseline_XGB.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Collaborative Filtering, matrix factorizaiton**"
      ],
      "metadata": {
        "id": "4ubMaqIb8vSO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Google colab version\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import pandas as pd\n",
        "df_final = pd.read_csv(\"/content/drive/My Drive/Thesis/Data/df_final_2.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJdsFNZXRKuW",
        "outputId": "220a1651-996d-4087-af9e-fe2a866d9843"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ImputationMatrixFactorization:\n",
        "    def __init__(self, R, K, alpha, beta, iterations):\n",
        "        self.R = R\n",
        "        self.num_users, self.num_items = R.shape\n",
        "        self.K = K\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "        self.iterations = iterations\n",
        "\n",
        "    def impute_missing_values(self):\n",
        "        imputer = SimpleImputer(strategy='mean')\n",
        "        self.R_imputed = imputer.fit_transform(self.R)\n",
        "\n",
        "    def train(self):\n",
        "        self.P = np.random.normal(scale=1./self.K, size=(self.num_users, self.K))\n",
        "        self.Q = np.random.normal(scale=1./self.K, size=(self.num_items, self.K))\n",
        "        self.b_u = np.zeros(self.num_users)\n",
        "        self.b_i = np.zeros(self.num_items)\n",
        "        self.b = np.mean(self.R_imputed[np.where(self.R_imputed != 0)])\n",
        "\n",
        "        self.samples = [\n",
        "            (i, j, self.R_imputed[i, j])\n",
        "            for i in range(self.num_users)\n",
        "            for j in range(self.num_items)\n",
        "            if self.R[i, j] > 0\n",
        "        ]\n",
        "\n",
        "        for i in range(self.iterations):\n",
        "            np.random.shuffle(self.samples)\n",
        "            self.sgd()\n",
        "            mse = self.mse()\n",
        "            if (i+1) % 10 == 0:\n",
        "                print(f\"Iteration: {i+1}; error = {mse:.4f}\")\n",
        "\n",
        "    def mse(self):\n",
        "        xs, ys = self.R.nonzero()\n",
        "        predicted = self.full_matrix()\n",
        "        error = 0\n",
        "        for x, y in zip(xs, ys):\n",
        "            error += (self.R[x, y] - predicted[x, y]) ** 2\n",
        "        return np.sqrt(error)\n",
        "\n",
        "    def sgd(self):\n",
        "        for i, j, r in self.samples:\n",
        "            prediction = self.get_prediction(i, j)\n",
        "            e = (r - prediction)\n",
        "\n",
        "            self.b_u[i] += self.alpha * (e - self.beta * self.b_u[i])\n",
        "            self.b_i[j] += self.alpha * (e - self.beta * self.b_i[j])\n",
        "\n",
        "            self.P[i, :] += self.alpha * (e * self.Q[j, :] - self.beta * self.P[i,:])\n",
        "            self.Q[j, :] += self.alpha * (e * self.P[i, :] - self.beta * self.Q[j,:])\n",
        "\n",
        "    def get_prediction(self, i, j):\n",
        "        prediction = self.b + self.b_u[i] + self.b_i[j] + self.P[i, :].dot(self.Q[j, :].T)\n",
        "        return prediction\n",
        "\n",
        "    def full_matrix(self):\n",
        "        return self.b + self.b_u[:,np.newaxis] + self.b_i[np.newaxis:,] + self.P.dot(self.Q.T)\n",
        "\n"
      ],
      "metadata": {
        "id": "FDzhuUqMVC2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "R_df = df_final.pivot(index='UserID', columns='MovieID', values='Rating')\n",
        "R = R_df.values\n",
        "\n",
        "imf = ImputationMatrixFactorization(R, K=2, alpha=0.01, beta=0.01, iterations=100)\n",
        "imf.impute_missing_values()\n",
        "imf.train()\n",
        "predicted_matrix = imf.full_matrix()\n",
        "print(predicted_matrix)\n",
        "\n",
        "# Evaluation\n",
        "def get_true_pred_ratings(df, predicted_df):\n",
        "    true_ratings = []\n",
        "    predicted_ratings = []\n",
        "    for row in df.itertuples():\n",
        "        user_id = row.UserID\n",
        "        movie_id = row.MovieID\n",
        "        true_ratings.append(row.Rating)\n",
        "        predicted_ratings.append(predicted_df.loc[user_id, movie_id])\n",
        "    return np.array(true_ratings), np.array(predicted_ratings)\n",
        "\n",
        "true_ratings, predicted_ratings = get_true_pred_ratings(df_final, pd.DataFrame(predicted_matrix, columns=R_df.columns, index=R_df.index))\n",
        "\n",
        "precision = precision_score(true_ratings, predicted_ratings.round(), average='weighted', zero_division=0)\n",
        "recall = recall_score(true_ratings, predicted_ratings.round(), average='weighted', zero_division=0)\n",
        "f1 = f1_score(true_ratings, predicted_ratings.round(), average='weighted', zero_division=0)\n",
        "accuracy = accuracy_score(true_ratings, predicted_ratings.round())\n",
        "\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dTrZ-FyU33q",
        "outputId": "6a37a73e-0b6a-42c0-b462-ff588ac9fa8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 10; error = nan\n",
            "Iteration: 20; error = nan\n",
            "Iteration: 30; error = nan\n",
            "Iteration: 40; error = nan\n",
            "Iteration: 50; error = nan\n",
            "Iteration: 60; error = nan\n",
            "Iteration: 70; error = nan\n",
            "Iteration: 80; error = nan\n",
            "Iteration: 90; error = nan\n",
            "Iteration: 100; error = nan\n",
            "[[4.46010186 3.60829331 3.43042852 ... 4.32580485 2.65673402 3.87182357]\n",
            " [4.14812481 3.34335054 3.14951091 ... 3.96385389 2.55786762 3.69507351]\n",
            " [4.27883658 3.44457187 3.23395441 ... 3.92351679 3.35727072 4.12188705]\n",
            " ...\n",
            " [4.46996054 4.18968623 3.91941883 ... 4.49668633 2.21048452 4.07896634]\n",
            " [4.19810411 3.50903944 3.27162849 ... 3.85862852 3.26002517 4.13844656]\n",
            " [3.44117644 1.93717885 1.8060465  ... 2.67968091 3.91627503 3.46236176]]\n",
            "Precision: 0.5177\n",
            "Recall: 0.4668\n",
            "F1 Score: 0.4472\n",
            "Accuracy: 0.4668\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OLD, NOT WORKING"
      ],
      "metadata": {
        "id": "aNwl1o8nA6Gk"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSzWKAfAlmji"
      },
      "source": [
        "## RF, HPT, (-2 features) -> Accuracy 0.46 (wrong data split)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZtsjBo3n4sSN"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV, KFold\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yktJncD-40Fn"
      },
      "outputs": [],
      "source": [
        "# Separate features and target\n",
        "X = df_final.drop(columns=['Rating'])\n",
        "y = df_final['Rating']\n",
        "\n",
        "# Perform stratified sampling for 40% of the data for increased efficiency\n",
        "X_sampled, _, y_sampled, _ = train_test_split(X, y, test_size=0.6, stratify=y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s9loRIQ545jT"
      },
      "outputs": [],
      "source": [
        "def evaluate_performance(y_true, y_pred):\n",
        "    print(f\"Accuracy: {accuracy_score(y_true, y_pred):.2f}\")\n",
        "    print(f\"Precision: {precision_score(y_true, y_pred, average='macro'):.2f}\")\n",
        "    print(f\"Recall: {recall_score(y_true, y_pred, average='macro'):.2f}\")\n",
        "    print(f\"F1 Score: {f1_score(y_true, y_pred, average='macro'):.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vcNDRFB5Hz7",
        "outputId": "6d749544-8a4c-4ce0-f55d-c81a62653673"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Nested Cross-Validation Accuracy: 0.46 ± 0.00\n"
          ]
        }
      ],
      "source": [
        "# Define the parameter grid for tuning\n",
        "param_dist = {\n",
        "    'n_estimators': [10, 50, 100],\n",
        "    'max_depth': [10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Define the inner and outer cross-validation strategies\n",
        "inner_cv = KFold(n_splits=3, shuffle=True, random_state=42)\n",
        "outer_cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize the RandomizedSearchCV\n",
        "random_search = RandomizedSearchCV(estimator=RandomForestClassifier(),\n",
        "                                   param_distributions=param_dist, n_iter=10,\n",
        "                                   cv=inner_cv, scoring='accuracy',\n",
        "                                   random_state=42)\n",
        "\n",
        "# Perform nested cross-validation\n",
        "nested_scores = cross_val_score(random_search, X_sampled, y_sampled,\n",
        "                                cv=outer_cv, scoring='accuracy')\n",
        "\n",
        "# Print the performance of the nested cross-validation\n",
        "print(f\"Nested Cross-Validation Accuracy: {nested_scores.mean():.2f} ± {nested_scores.std():.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhKdMWVf5dVW",
        "outputId": "a96918c5-a614-42f3-ec27-24fd58ac0be5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Set Performance:\n",
            "Accuracy: 0.46\n",
            "Precision: 0.47\n",
            "Recall: 0.38\n",
            "F1 Score: 0.40\n",
            "Test Set Performance:\n",
            "Accuracy: 0.45\n",
            "Precision: 0.47\n",
            "Recall: 0.38\n",
            "F1 Score: 0.40\n"
          ]
        }
      ],
      "source": [
        "# Split the data into training, validation, and test sets (60%, 20%, 20%)\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X_sampled, y_sampled, test_size=0.4, stratify=y_sampled)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp)\n",
        "\n",
        "# Fit the best model found by the random search on the full training set\n",
        "random_search.fit(X_train, y_train)\n",
        "best_model = random_search.best_estimator_\n",
        "\n",
        "# Evaluate the best model on the validation set\n",
        "val_predictions = best_model.predict(X_val)\n",
        "print(\"Validation Set Performance:\")\n",
        "evaluate_performance(y_val, val_predictions)\n",
        "\n",
        "# Evaluate the best model on the test set\n",
        "test_predictions = best_model.predict(X_test)\n",
        "print(\"Test Set Performance:\")\n",
        "evaluate_performance(y_test, test_predictions)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfyS-D6SF_8o"
      },
      "source": [
        "## RF, HPT, (-2 features) -> Accuracy 0.46 (no val scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JL34YlYdJ4ic"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score, KFold\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IlIo-8AaGDFK"
      },
      "outputs": [],
      "source": [
        "# Load in the dataframe\n",
        "df_final = pd.read_csv(\"/content/drive/My Drive/Thesis/Data/df_sampled_unscaled.csv\")\n",
        "df_final = df_final.drop(columns=['Dev_movie_avg',\t'Total_ratings_per_user'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wd17i20TxCHT"
      },
      "outputs": [],
      "source": [
        "# Separate features and target\n",
        "X = df_final.drop(columns=['Rating'])\n",
        "y = df_final['Rating']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HXrs_N3uKTCE"
      },
      "outputs": [],
      "source": [
        "# Split sampled data into 80% training, 20% testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
        "                                                    stratify=y,\n",
        "                                                    random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8lbUc57HKWmt"
      },
      "outputs": [],
      "source": [
        "# Evaluation function\n",
        "def evaluate_performance(y_true, y_pred):\n",
        "    print(f\"Accuracy: {accuracy_score(y_true, y_pred):.2f}\")\n",
        "    print(f\"Precision: {precision_score(y_true, y_pred, average='macro'):.2f}\")\n",
        "    print(f\"Recall: {recall_score(y_true, y_pred, average='macro'):.2f}\")\n",
        "    print(f\"F1 Score: {f1_score(y_true, y_pred, average='macro'):.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CekRPkcBKZIJ"
      },
      "outputs": [],
      "source": [
        "# Define the parameter grid for tuning\n",
        "\n",
        "param_dist = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20, 30, 40],\n",
        "    'min_samples_split': [2, 5, 10, 15],\n",
        "    'min_samples_leaf': [1, 2, 4, 6]\n",
        "}\n",
        "\n",
        "# Define the inner and outer cross-validation strategies\n",
        "inner_cv = KFold(n_splits=3, shuffle=True, random_state=42)\n",
        "outer_cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize the RandomizedSearchCV\n",
        "random_search = RandomizedSearchCV(estimator=RandomForestClassifier(),\n",
        "                                   param_distributions=param_dist, n_iter=15,\n",
        "                                   cv=inner_cv, scoring='accuracy',\n",
        "                                   random_state=42)\n",
        "\n",
        "# Perform nested cross-validation and store best parameters for each fold\n",
        "nested_scores = []\n",
        "best_params = []\n",
        "best_models = []\n",
        "\n",
        "for train_idx, test_idx in outer_cv.split(X_train, y_train):\n",
        "    random_search.fit(X_train.iloc[train_idx], y_train.iloc[train_idx])\n",
        "    nested_scores.append(random_search.best_score_)\n",
        "    best_params.append(random_search.best_params_)\n",
        "    best_model = random_search.best_estimator_\n",
        "    best_models.append(best_model)\n",
        "\n",
        "# Print the performance of the nested cross-validation\n",
        "print(f\"Nested Cross-Validation Accuracy: {np.mean(nested_scores):.2f} ± {np.std(nested_scores):.2f}\")\n",
        "\n",
        "# Print the best parameters found for each fold\n",
        "print(\"Best parameters for each fold:\")\n",
        "for params in best_params:\n",
        "    print(params)\n",
        "\n",
        "# Use the best model found in the outer loop\n",
        "final_best_model = best_models[-1]\n",
        "\n",
        "# Evaluate the best model on the test set\n",
        "test_predictions = final_best_model.predict(X_test)\n",
        "print(\"Test Set Performance:\")\n",
        "evaluate_performance(y_test, test_predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCgNzr7bxfut",
        "outputId": "1a08c302-e49f-409f-9cfc-fde584d1c0d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Set Performance:\n",
            "Accuracy: 0.46\n",
            "Precision: 0.48\n",
            "Recall: 0.37\n",
            "F1 Score: 0.39\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the best model on the test set\n",
        "test_predictions = final_best_model.predict(X_test)\n",
        "print(\"Test Set Performance:\")\n",
        "evaluate_performance(y_test, test_predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 29/10 Random Forest with hyperparameter tuning (new sample_df)"
      ],
      "metadata": {
        "id": "eCVUmX5Oweh7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import KFold, train_test_split, RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
      ],
      "metadata": {
        "id": "fucRqTrmx86U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define feature and target\n",
        "X = df_final.drop('Rating', axis=1)\n",
        "y = df_final['Rating']"
      ],
      "metadata": {
        "id": "bLvFWFIbx8Wt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data 80% train, 20% test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
      ],
      "metadata": {
        "id": "PP3Yin5oyF-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the parameter grid for hyperparameter optimization\n",
        "param_dist = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}"
      ],
      "metadata": {
        "id": "eiTdzgQb2Kkb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the inner and outer cross-validation strategies\n",
        "inner_cv = KFold(n_splits=3, shuffle=True, random_state=42)\n",
        "outer_cv = KFold(n_splits=5, shuffle=True, random_state=42)"
      ],
      "metadata": {
        "id": "v_VB5FI32MhB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the RandomizedSearchCV\n",
        "random_search = RandomizedSearchCV(estimator=RandomForestClassifier(),\n",
        "                                   param_distributions=param_dist, n_iter=15,\n",
        "                                   cv=inner_cv, scoring='accuracy',\n",
        "                                   random_state=42)\n",
        "\n",
        "# Perform nested cross-validation\n",
        "outer_scores = []\n",
        "val_scores = []\n",
        "\n",
        "for train_idx, val_idx in outer_cv.split(X_train, y_train):\n",
        "    # Split the data into training and validation sets\n",
        "    X_train_fold = X_train.iloc[train_idx]\n",
        "    X_val_fold = X_train.iloc[val_idx]\n",
        "    y_train_fold = y_train.iloc[train_idx]\n",
        "    y_val_fold = y_train.iloc[val_idx]\n",
        "\n",
        "    # Fit the model on the training fold\n",
        "    random_search.fit(X_train_fold, y_train_fold)\n",
        "    best_model = random_search.best_estimator_\n",
        "\n",
        "    # Evaluate on the validation set\n",
        "    val_predictions = best_model.predict(X_val_fold)\n",
        "    val_acc = accuracy_score(y_val_fold, val_predictions)\n",
        "    val_prec = precision_score(y_val_fold, val_predictions, average='weighted')\n",
        "    val_rec = recall_score(y_val_fold, val_predictions, average='weighted')\n",
        "    val_f1 = f1_score(y_val_fold, val_predictions, average='weighted')\n",
        "\n",
        "    # Append validation metrics\n",
        "    val_scores.append((val_acc, val_prec, val_rec, val_f1))\n",
        "\n",
        "    # Store the outer fold score (accuracy)\n",
        "    outer_scores.append(random_search.best_score_)\n",
        "\n",
        "# Print the performance of the nested cross-validation\n",
        "print(f\"Nested Cross-Validation Accuracy: {np.mean(outer_scores):.2f} ± {np.std(outer_scores):.2f}\")\n",
        "\n",
        "# Print validation set performance for each fold\n",
        "val_scores = np.array(val_scores)\n",
        "print(\"Validation Set Performance:\")\n",
        "print(f\"Accuracy: {val_scores[:, 0].mean():.2f} ± {val_scores[:, 0].std():.2f}\")\n",
        "print(f\"Precision: {val_scores[:, 1].mean():.2f} ± {val_scores[:, 1].std():.2f}\")\n",
        "print(f\"Recall: {val_scores[:, 2].mean():.2f} ± {val_scores[:, 2].std():.2f}\")\n",
        "print(f\"F1 Score: {val_scores[:, 3].mean():.2f} ± {val_scores[:, 3].std():.2f}\")\n",
        "\n",
        "# Fit the best model found on the entire training set\n",
        "random_search.fit(X_train, y_train)\n",
        "best_model = random_search.best_estimator_\n",
        "\n",
        "# Evaluate on the test set\n",
        "test_predictions = best_model.predict(X_test)\n",
        "print(\"Test Set Performance:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, test_predictions):.2f}\")\n",
        "print(f\"Precision: {precision_score(y_test, test_predictions, average='weighted'):.2f}\")\n",
        "print(f\"Recall: {recall_score(y_test, test_predictions, average='weighted'):.2f}\")\n",
        "print(f\"F1 Score: {f1_score(y_test, test_predictions, average='weighted'):.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGqRKHnS1IpG",
        "outputId": "2d7de325-8216-4e49-bb85-ec9c505ae543"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/ma/core.py:2820: RuntimeWarning: invalid value encountered in cast\n",
            "  _data = np.array(data, dtype=dtype, copy=copy,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nested Cross-Validation Accuracy: 0.41 ± 0.00\n",
            "Validation Set Performance:\n",
            "Accuracy: 0.41 ± 0.00\n",
            "Precision: 0.42 ± 0.00\n",
            "Recall: 0.41 ± 0.00\n",
            "F1 Score: 0.38 ± 0.00\n",
            "Test Set Performance:\n",
            "Accuracy: 0.42\n",
            "Precision: 0.43\n",
            "Recall: 0.42\n",
            "F1 Score: 0.39\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 30/10 Random Forest with hyperparameter tuning, sample_df_3010\n",
        "\n"
      ],
      "metadata": {
        "id": "zZrrOYIsKdMf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import KFold, train_test_split, RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
      ],
      "metadata": {
        "id": "8CXJEMGrGBUH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df_final = pd.read_csv(\"/content/drive/My Drive/Thesis/Data/sample_df_3010.csv\")"
      ],
      "metadata": {
        "id": "-YN_M1q-KrPp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define feature and target\n",
        "X = df_final.drop('Rating', axis=1)\n",
        "y = df_final['Rating']"
      ],
      "metadata": {
        "id": "dXQf_r3EKwdI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data 80% train, 20% test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
        "                                                    stratify=y, random_state=42)"
      ],
      "metadata": {
        "id": "IsZuQxQBK2yZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the parameter grid for hyperparameter optimization\n",
        "param_dist = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}"
      ],
      "metadata": {
        "id": "swRSySiMK8-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the inner and outer cross-validation strategies\n",
        "inner_cv = KFold(n_splits=3, shuffle=True, random_state=42)\n",
        "outer_cv = KFold(n_splits=5, shuffle=True, random_state=42)"
      ],
      "metadata": {
        "id": "8EqtE9QCLA8j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the RandomizedSearchCV\n",
        "random_search = RandomizedSearchCV(estimator=RandomForestClassifier(),\n",
        "                                   param_distributions=param_dist, n_iter=15,\n",
        "                                   cv=inner_cv, scoring='accuracy',\n",
        "                                   random_state=42)\n",
        "\n",
        "\n",
        "\n",
        "# Perform nested cross-validation\n",
        "outer_scores = []\n",
        "val_scores = []\n",
        "\n",
        "for train_idx, val_idx in outer_cv.split(X_train, y_train):\n",
        "    # Split the data into training and validation sets\n",
        "    X_train_fold = X_train.iloc[train_idx]\n",
        "    X_val_fold = X_train.iloc[val_idx]\n",
        "    y_train_fold = y_train.iloc[train_idx]\n",
        "    y_val_fold = y_train.iloc[val_idx]\n",
        "\n",
        "    # Fit the model on the training fold\n",
        "    random_search.fit(X_train_fold, y_train_fold)\n",
        "    best_model = random_search.best_estimator_\n",
        "\n",
        "    # Evaluate on the validation set\n",
        "    val_predictions = best_model.predict(X_val_fold)\n",
        "    val_acc = accuracy_score(y_val_fold, val_predictions)\n",
        "    val_prec = precision_score(y_val_fold, val_predictions, average='weighted')\n",
        "    val_rec = recall_score(y_val_fold, val_predictions, average='weighted')\n",
        "    val_f1 = f1_score(y_val_fold, val_predictions, average='weighted')\n",
        "\n",
        "    # Append validation metrics\n",
        "    val_scores.append((val_acc, val_prec, val_rec, val_f1))\n",
        "\n",
        "    # Store the outer fold score (accuracy)\n",
        "    outer_scores.append(random_search.best_score_)\n",
        "\n",
        "# Print the performance of the nested cross-validation\n",
        "print(f\"Nested Cross-Validation Accuracy: {np.mean(outer_scores):.2f} ± {np.std(outer_scores):.2f}\")\n",
        "\n",
        "# Print validation set performance for each fold\n",
        "val_scores = np.array(val_scores)\n",
        "print(\"Validation Set Performance:\")\n",
        "print(f\"Accuracy: {val_scores[:, 0].mean():.2f} ± {val_scores[:, 0].std():.2f}\")\n",
        "print(f\"Precision: {val_scores[:, 1].mean():.2f} ± {val_scores[:, 1].std():.2f}\")\n",
        "print(f\"Recall: {val_scores[:, 2].mean():.2f} ± {val_scores[:, 2].std():.2f}\")\n",
        "print(f\"F1 Score: {val_scores[:, 3].mean():.2f} ± {val_scores[:, 3].std():.2f}\")\n",
        "\n",
        "# Fit the best model found on the entire training set\n",
        "random_search.fit(X_train, y_train)\n",
        "best_model = random_search.best_estimator_\n",
        "\n",
        "# Evaluate on the test set\n",
        "test_predictions = best_model.predict(X_test)\n",
        "print(\"Test Set Performance:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, test_predictions):.2f}\")\n",
        "print(f\"Precision: {precision_score(y_test, test_predictions, average='weighted'):.2f}\")\n",
        "print(f\"Recall: {recall_score(y_test, test_predictions, average='weighted'):.2f}\")\n",
        "print(f\"F1 Score: {f1_score(y_test, test_predictions, average='weighted'):.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1OnqhvyLJtI",
        "outputId": "54768b1c-1f0d-487f-a47f-8903d40490bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/ma/core.py:2820: RuntimeWarning: invalid value encountered in cast\n",
            "  _data = np.array(data, dtype=dtype, copy=copy,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nested Cross-Validation Accuracy: 0.40 ± 0.00\n",
            "Validation Set Performance:\n",
            "Accuracy: 0.41 ± 0.00\n",
            "Precision: 0.42 ± 0.00\n",
            "Recall: 0.41 ± 0.00\n",
            "F1 Score: 0.38 ± 0.00\n",
            "Test Set Performance:\n",
            "Accuracy: 0.41\n",
            "Precision: 0.42\n",
            "Recall: 0.41\n",
            "F1 Score: 0.38\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  27/10 Random Forest with hyperparameter tuning (-2 features) -> Accuracy ?"
      ],
      "metadata": {
        "id": "QlzlLlOU2oyr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import KFold, train_test_split, RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
      ],
      "metadata": {
        "id": "GdkmEXbM2oPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load df Google Colab (feature engineered, encoded, scaled/unscaled)\n",
        "df_final = pd.read_csv(\"/content/drive/My Drive/Thesis/Data/df_sampled_unscaled.csv\")\n",
        "df_final = df_final.drop(columns=['Dev_movie_avg',\t'Total_ratings_per_user'])"
      ],
      "metadata": {
        "id": "44d_4d7X2z24"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define feature and target\n",
        "X = df_final.drop('Rating', axis=1)\n",
        "y = df_final['Rating']"
      ],
      "metadata": {
        "id": "TkvdFdID29gC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data 80% train, 20% test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
      ],
      "metadata": {
        "id": "8BnvCm5U3AZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the parameter grid for hyperparameter optimization\n",
        "param_dist = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}"
      ],
      "metadata": {
        "id": "YP9qpqb43Dax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the inner and outer cross-validation strategies\n",
        "inner_cv = KFold(n_splits=3, shuffle=True, random_state=42)\n",
        "outer_cv = KFold(n_splits=5, shuffle=True, random_state=42)"
      ],
      "metadata": {
        "id": "Iir4h6xM3Gz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the RandomizedSearchCV\n",
        "random_search = RandomizedSearchCV(estimator=RandomForestClassifier(),\n",
        "                                   param_distributions=param_dist, n_iter=15,\n",
        "                                   cv=inner_cv, scoring='accuracy',\n",
        "                                   random_state=42)\n",
        "\n",
        "# Perform nested cross-validation\n",
        "outer_scores = []\n",
        "val_scores = []\n",
        "\n",
        "for train_idx, val_idx in outer_cv.split(X_train, y_train):\n",
        "    # Split the data into training and validation sets\n",
        "    X_train_fold = X_train.iloc[train_idx]\n",
        "    X_val_fold = X_train.iloc[val_idx]\n",
        "    y_train_fold = y_train.iloc[train_idx]\n",
        "    y_val_fold = y_train.iloc[val_idx]\n",
        "\n",
        "    # Fit the model on the training fold\n",
        "    random_search.fit(X_train_fold, y_train_fold)\n",
        "    best_model = random_search.best_estimator_\n",
        "\n",
        "    # Evaluate on the validation set\n",
        "    val_predictions = best_model.predict(X_val_fold)\n",
        "    val_acc = accuracy_score(y_val_fold, val_predictions)\n",
        "    val_prec = precision_score(y_val_fold, val_predictions, average='weighted')\n",
        "    val_rec = recall_score(y_val_fold, val_predictions, average='weighted')\n",
        "    val_f1 = f1_score(y_val_fold, val_predictions, average='weighted')\n",
        "\n",
        "    # Append validation metrics\n",
        "    val_scores.append((val_acc, val_prec, val_rec, val_f1))\n",
        "\n",
        "    # Store the outer fold score (accuracy)\n",
        "    outer_scores.append(random_search.best_score_)\n",
        "\n",
        "# Print the performance of the nested cross-validation\n",
        "print(f\"Nested Cross-Validation Accuracy: {np.mean(outer_scores):.2f} ± {np.std(outer_scores):.2f}\")\n",
        "\n",
        "# Print validation set performance for each fold\n",
        "val_scores = np.array(val_scores)\n",
        "print(\"Validation Set Performance:\")\n",
        "print(f\"Accuracy: {val_scores[:, 0].mean():.2f} ± {val_scores[:, 0].std():.2f}\")\n",
        "print(f\"Precision: {val_scores[:, 1].mean():.2f} ± {val_scores[:, 1].std():.2f}\")\n",
        "print(f\"Recall: {val_scores[:, 2].mean():.2f} ± {val_scores[:, 2].std():.2f}\")\n",
        "print(f\"F1 Score: {val_scores[:, 3].mean():.2f} ± {val_scores[:, 3].std():.2f}\")\n",
        "\n",
        "# Fit the best model found on the entire training set\n",
        "random_search.fit(X_train, y_train)\n",
        "best_model = random_search.best_estimator_\n",
        "\n",
        "# Evaluate on the test set\n",
        "test_predictions = best_model.predict(X_test)\n",
        "print(\"Test Set Performance:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, test_predictions):.2f}\")\n",
        "print(f\"Precision: {precision_score(y_test, test_predictions, average='weighted'):.2f}\")\n",
        "print(f\"Recall: {recall_score(y_test, test_predictions, average='weighted'):.2f}\")\n",
        "print(f\"F1 Score: {f1_score(y_test, test_predictions, average='weighted'):.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAT99scw3LUc",
        "outputId": "01fad123-0bb3-4347-8852-96e12bdeeedb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nested Cross-Validation Accuracy: 0.46 ± 0.00\n",
            "Validation Set Performance:\n",
            "Accuracy: 0.46 ± 0.00\n",
            "Precision: 0.47 ± 0.00\n",
            "Recall: 0.46 ± 0.00\n",
            "F1 Score: 0.44 ± 0.00\n",
            "Test Set Performance:\n",
            "Accuracy: 0.46\n",
            "Precision: 0.47\n",
            "Recall: 0.46\n",
            "F1 Score: 0.45\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2slKv5PUb61g"
      },
      "source": [
        "## Gradient boosting with hyperparameter tuning (-2 features) -> Accuracy 0.46\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HfOwssYDb_On"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV, KFold\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load df Google Colab (feature engineered, encoded, scaled/unscaled)\n",
        "df_sampled_unscaled = pd.read_csv(\"/content/drive/My Drive/Thesis/Data/df_sampled_unscaled.csv\")\n",
        "df_sampled_scaled = pd.read_csv(\"/content/drive/My Drive/Thesis/Data/df_sampled_scaled.csv\")"
      ],
      "metadata": {
        "id": "SAevHd6ZrOc3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_final = df_sampled_unscaled.copy()\n",
        "df_final = df_final.drop(columns=['Dev_movie_avg',\t'Total_ratings_per_user'])"
      ],
      "metadata": {
        "id": "5sn4jTkhrN5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OhzrjZYSR-Nu"
      },
      "outputs": [],
      "source": [
        "# Separate features and target\n",
        "X = df_final.drop(columns=['Rating'])\n",
        "y = df_final['Rating']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GP55Vcv9cGXH"
      },
      "outputs": [],
      "source": [
        "# Split data into 80% training, 20% testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gTVqY2_bcIUT"
      },
      "outputs": [],
      "source": [
        "# Define evaluation function\n",
        "def evaluate_performance(y_true, y_pred):\n",
        "    print(f\"Accuracy: {accuracy_score(y_true, y_pred):.2f}\")\n",
        "    print(f\"Precision: {precision_score(y_true, y_pred, average='macro'):.2f}\")\n",
        "    print(f\"Recall: {recall_score(y_true, y_pred, average='macro'):.2f}\")\n",
        "    print(f\"F1 Score: {f1_score(y_true, y_pred, average='macro'):.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZ8nSvgNcJUj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c911d2fe-726e-439e-b8b7-f71ebafca7d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nested Cross-Validation Accuracy: 0.46 ± 0.00\n",
            "Best parameters for each fold:\n",
            "{'n_estimators': 50, 'max_depth': 7, 'learning_rate': 0.1}\n",
            "{'n_estimators': 50, 'max_depth': 7, 'learning_rate': 0.1}\n",
            "{'n_estimators': 50, 'max_depth': 7, 'learning_rate': 0.1}\n",
            "{'n_estimators': 50, 'max_depth': 7, 'learning_rate': 0.1}\n",
            "{'n_estimators': 50, 'max_depth': 7, 'learning_rate': 0.1}\n",
            "Test Set Performance:\n",
            "Accuracy: 0.46\n",
            "Precision: 0.46\n",
            "Recall: 0.38\n",
            "F1 Score: 0.40\n"
          ]
        }
      ],
      "source": [
        "from joblib import Parallel, delayed\n",
        "\n",
        "# Define the parameter grid for tuning\n",
        "param_dist = {\n",
        "    'n_estimators': [50, 100, 150, 200],\n",
        "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
        "    'max_depth': [3, 7, 10, 20]\n",
        "}\n",
        "\n",
        "# Define the inner and outer cross-validation strategies\n",
        "inner_cv = KFold(n_splits=3, shuffle=True, random_state=42)\n",
        "outer_cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize the RandomizedSearchCV\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=GradientBoostingClassifier(),\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=15,\n",
        "    cv=inner_cv,\n",
        "    scoring='accuracy',\n",
        "    random_state=42,\n",
        "    n_jobs=-1  # Utilize all available cores for parallel processing\n",
        ")\n",
        "\n",
        "# Perform nested cross-validation and store best parameters for each fold\n",
        "nested_scores = []\n",
        "best_params = []\n",
        "best_models = []\n",
        "\n",
        "def fit_and_evaluate(train_idx, test_idx):\n",
        "    random_search.fit(X_train.iloc[train_idx], y_train.iloc[train_idx])\n",
        "    best_model = random_search.best_estimator_\n",
        "    return random_search.best_score_, random_search.best_params_, best_model\n",
        "\n",
        "results = Parallel(n_jobs=-1)(delayed(fit_and_evaluate)(train_idx, test_idx) for train_idx, test_idx in outer_cv.split(X_train, y_train))\n",
        "\n",
        "for score, params, model in results:\n",
        "    nested_scores.append(score)\n",
        "    best_params.append(params)\n",
        "    best_models.append(model)\n",
        "\n",
        "# Print the performance of the nested cross-validation\n",
        "print(f\"Nested Cross-Validation Accuracy: {np.mean(nested_scores):.2f} ± {np.std(nested_scores):.2f}\")\n",
        "\n",
        "# Print the best parameters found for each fold\n",
        "print(\"Best parameters for each fold:\")\n",
        "for params in best_params:\n",
        "    print(params)\n",
        "\n",
        "# Use the best model found in the outer loop\n",
        "final_best_model = best_models[-1]\n",
        "\n",
        "# Evaluate the best model on the test set\n",
        "test_predictions = final_best_model.predict(X_test)\n",
        "print(\"Test Set Performance:\")\n",
        "evaluate_performance(y_test, test_predictions)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **BASELINE RANDOM FOREST 10/11, df_final_2**\n",
        "\n",
        "> Good dataframe, not good that gridcv is ran twice!!\n",
        "\n"
      ],
      "metadata": {
        "id": "WCOZqmHflSan"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Google colab version\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UmS816MclWFW",
        "outputId": "7397fa59-cae0-4692-8223-8c2ef1121a4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load df Google Colab (feature engineered, encoded, scaled/unscaled)\n",
        "import pandas as pd\n",
        "df_final = pd.read_csv(\"/content/drive/My Drive/Thesis/Data/df_final_2.csv\")\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "df_final.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "id": "9ZKt1Tg7liNw",
        "outputId": "b4d2a14c-57a8-4570-d998-ecc46fe7f6ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   UserID  MovieID  Rating  Age  Year  Month  Day  Hour  Release_year  \\\n",
              "0    5616     3590       3    4  2000      5   24     2          1974   \n",
              "1    4060       21       4    2  2000      8    5    15          1995   \n",
              "2    1125     3273       2    1  2000     11   22    16          2000   \n",
              "3    3410      585       4    3  2000      8   27    22          1995   \n",
              "4    3675     1374       4    3  2000      8   15    18          1982   \n",
              "\n",
              "   Time_release_to_rating  Total_ratings_per_movie  Total_ratings_per_user  \\\n",
              "0                      26                       85                     130   \n",
              "1                       5                     1356                     256   \n",
              "2                       0                      577                     580   \n",
              "3                       5                      418                     731   \n",
              "4                      18                     1448                     849   \n",
              "\n",
              "   Female   Male  Academic/educator  Artist  Clerical/admin  \\\n",
              "0   False   True               True   False           False   \n",
              "1   False   True              False   False           False   \n",
              "2    True  False              False   False           False   \n",
              "3   False   True               True   False           False   \n",
              "4   False   True              False   False           False   \n",
              "\n",
              "   College/grad student  Customer service  Doctor/health care  \\\n",
              "0                 False             False               False   \n",
              "1                 False             False               False   \n",
              "2                  True             False               False   \n",
              "3                 False             False               False   \n",
              "4                 False             False               False   \n",
              "\n",
              "   Executive/managerial  Farmer  Homemaker  K-12 student  Lawyer  \\\n",
              "0                 False   False      False         False   False   \n",
              "1                 False   False      False         False   False   \n",
              "2                 False   False      False         False   False   \n",
              "3                 False   False      False         False   False   \n",
              "4                  True   False      False         False   False   \n",
              "\n",
              "   Other or not specified  Programmer  Retired  Sales/marketing  Scientist  \\\n",
              "0                   False       False    False            False      False   \n",
              "1                   False       False    False            False      False   \n",
              "2                   False       False    False            False      False   \n",
              "3                   False       False    False            False      False   \n",
              "4                   False       False    False            False      False   \n",
              "\n",
              "   Self-employed  Technician/engineer  Tradesman/craftsman  Unemployed  \\\n",
              "0          False                False                False       False   \n",
              "1          False                False                 True       False   \n",
              "2          False                False                False       False   \n",
              "3          False                False                False       False   \n",
              "4          False                False                False       False   \n",
              "\n",
              "   Writer  Action  Adventure  Animation  Children's  Comedy  Crime  \\\n",
              "0   False   False      False      False       False    True  False   \n",
              "1   False    True      False      False       False    True  False   \n",
              "2   False   False      False      False       False   False  False   \n",
              "3   False   False      False      False       False    True  False   \n",
              "4   False    True       True      False       False   False  False   \n",
              "\n",
              "   Documentary  Drama  Fantasy  Film-Noir  Horror  Musical  Mystery  Romance  \\\n",
              "0        False  False    False      False   False    False    False    False   \n",
              "1        False   True    False      False   False    False    False    False   \n",
              "2        False  False    False      False    True    False     True    False   \n",
              "3        False  False    False      False   False    False    False    False   \n",
              "4        False  False    False      False   False    False    False    False   \n",
              "\n",
              "   Sci-Fi  Thriller    War  Western  Favourite_Action  Favourite_Adventure  \\\n",
              "0   False     False  False    False             False                False   \n",
              "1   False     False  False    False             False                False   \n",
              "2   False      True  False    False             False                False   \n",
              "3   False     False  False    False             False                False   \n",
              "4    True     False  False    False             False                False   \n",
              "\n",
              "   Favourite_Animation  Favourite_Children's  Favourite_Comedy  \\\n",
              "0                False                 False             False   \n",
              "1                False                 False             False   \n",
              "2                False                 False             False   \n",
              "3                False                 False             False   \n",
              "4                False                 False             False   \n",
              "\n",
              "   Favourite_Crime  Favourite_Documentary  Favourite_Drama  Favourite_Fantasy  \\\n",
              "0            False                  False            False              False   \n",
              "1            False                  False            False              False   \n",
              "2            False                  False            False              False   \n",
              "3            False                  False            False              False   \n",
              "4            False                  False            False              False   \n",
              "\n",
              "   Favourite_Film-Noir  Favourite_Horror  Favourite_Musical  \\\n",
              "0                False             False              False   \n",
              "1                False             False              False   \n",
              "2                 True             False              False   \n",
              "3                 True             False              False   \n",
              "4                 True             False              False   \n",
              "\n",
              "   Favourite_Mystery  Favourite_Romance  Favourite_Sci-Fi  Favourite_Thriller  \\\n",
              "0              False              False             False               False   \n",
              "1              False              False             False               False   \n",
              "2              False              False             False               False   \n",
              "3              False              False             False               False   \n",
              "4              False              False             False               False   \n",
              "\n",
              "   Favourite_War  Favourite_Western  \n",
              "0          False               True  \n",
              "1          False               True  \n",
              "2          False              False  \n",
              "3          False              False  \n",
              "4          False              False  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7e48e71e-6904-4a3d-b20e-19e8527c52a3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UserID</th>\n",
              "      <th>MovieID</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Age</th>\n",
              "      <th>Year</th>\n",
              "      <th>Month</th>\n",
              "      <th>Day</th>\n",
              "      <th>Hour</th>\n",
              "      <th>Release_year</th>\n",
              "      <th>Time_release_to_rating</th>\n",
              "      <th>Total_ratings_per_movie</th>\n",
              "      <th>Total_ratings_per_user</th>\n",
              "      <th>Female</th>\n",
              "      <th>Male</th>\n",
              "      <th>Academic/educator</th>\n",
              "      <th>Artist</th>\n",
              "      <th>Clerical/admin</th>\n",
              "      <th>College/grad student</th>\n",
              "      <th>Customer service</th>\n",
              "      <th>Doctor/health care</th>\n",
              "      <th>Executive/managerial</th>\n",
              "      <th>Farmer</th>\n",
              "      <th>Homemaker</th>\n",
              "      <th>K-12 student</th>\n",
              "      <th>Lawyer</th>\n",
              "      <th>Other or not specified</th>\n",
              "      <th>Programmer</th>\n",
              "      <th>Retired</th>\n",
              "      <th>Sales/marketing</th>\n",
              "      <th>Scientist</th>\n",
              "      <th>Self-employed</th>\n",
              "      <th>Technician/engineer</th>\n",
              "      <th>Tradesman/craftsman</th>\n",
              "      <th>Unemployed</th>\n",
              "      <th>Writer</th>\n",
              "      <th>Action</th>\n",
              "      <th>Adventure</th>\n",
              "      <th>Animation</th>\n",
              "      <th>Children's</th>\n",
              "      <th>Comedy</th>\n",
              "      <th>Crime</th>\n",
              "      <th>Documentary</th>\n",
              "      <th>Drama</th>\n",
              "      <th>Fantasy</th>\n",
              "      <th>Film-Noir</th>\n",
              "      <th>Horror</th>\n",
              "      <th>Musical</th>\n",
              "      <th>Mystery</th>\n",
              "      <th>Romance</th>\n",
              "      <th>Sci-Fi</th>\n",
              "      <th>Thriller</th>\n",
              "      <th>War</th>\n",
              "      <th>Western</th>\n",
              "      <th>Favourite_Action</th>\n",
              "      <th>Favourite_Adventure</th>\n",
              "      <th>Favourite_Animation</th>\n",
              "      <th>Favourite_Children's</th>\n",
              "      <th>Favourite_Comedy</th>\n",
              "      <th>Favourite_Crime</th>\n",
              "      <th>Favourite_Documentary</th>\n",
              "      <th>Favourite_Drama</th>\n",
              "      <th>Favourite_Fantasy</th>\n",
              "      <th>Favourite_Film-Noir</th>\n",
              "      <th>Favourite_Horror</th>\n",
              "      <th>Favourite_Musical</th>\n",
              "      <th>Favourite_Mystery</th>\n",
              "      <th>Favourite_Romance</th>\n",
              "      <th>Favourite_Sci-Fi</th>\n",
              "      <th>Favourite_Thriller</th>\n",
              "      <th>Favourite_War</th>\n",
              "      <th>Favourite_Western</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5616</td>\n",
              "      <td>3590</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>2000</td>\n",
              "      <td>5</td>\n",
              "      <td>24</td>\n",
              "      <td>2</td>\n",
              "      <td>1974</td>\n",
              "      <td>26</td>\n",
              "      <td>85</td>\n",
              "      <td>130</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4060</td>\n",
              "      <td>21</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2000</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>15</td>\n",
              "      <td>1995</td>\n",
              "      <td>5</td>\n",
              "      <td>1356</td>\n",
              "      <td>256</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1125</td>\n",
              "      <td>3273</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2000</td>\n",
              "      <td>11</td>\n",
              "      <td>22</td>\n",
              "      <td>16</td>\n",
              "      <td>2000</td>\n",
              "      <td>0</td>\n",
              "      <td>577</td>\n",
              "      <td>580</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3410</td>\n",
              "      <td>585</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2000</td>\n",
              "      <td>8</td>\n",
              "      <td>27</td>\n",
              "      <td>22</td>\n",
              "      <td>1995</td>\n",
              "      <td>5</td>\n",
              "      <td>418</td>\n",
              "      <td>731</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3675</td>\n",
              "      <td>1374</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2000</td>\n",
              "      <td>8</td>\n",
              "      <td>15</td>\n",
              "      <td>18</td>\n",
              "      <td>1982</td>\n",
              "      <td>18</td>\n",
              "      <td>1448</td>\n",
              "      <td>849</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7e48e71e-6904-4a3d-b20e-19e8527c52a3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7e48e71e-6904-4a3d-b20e-19e8527c52a3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7e48e71e-6904-4a3d-b20e-19e8527c52a3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7aba73a8-08be-4999-8d09-a86cc4557e35\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7aba73a8-08be-4999-8d09-a86cc4557e35')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7aba73a8-08be-4999-8d09-a86cc4557e35 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_final"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import KFold, train_test_split, RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
      ],
      "metadata": {
        "id": "Qu86mr3ylylx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define feature and target\n",
        "X = df_final.drop('Rating', axis=1)\n",
        "y = df_final['Rating']\n",
        "\n",
        "# Split data 80% train, 20% test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
        "                                                    stratify=y, random_state=42)\n",
        "\n",
        "# Define the parameter grid for hyperparameter optimization\n",
        "param_dist = {\n",
        "    'n_estimators': [100, 200, 250, 300],\n",
        "    'max_depth': [20, 30, 40, 50],\n",
        "    'min_samples_split': [2,5,10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Define the inner and outer cross-validation strategies\n",
        "inner_cv = KFold(n_splits=3, shuffle=True, random_state=42)\n",
        "outer_cv = KFold(n_splits=5, shuffle=True, random_state=42)"
      ],
      "metadata": {
        "id": "B4Ei-K9Vl1Lb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Turning booleans into numerical values\n",
        "#df_final = np.nan_to_num(df_final)\n",
        "df_final.astype(np.int32)"
      ],
      "metadata": {
        "id": "unl_sSwBGZBr",
        "outputId": "ef9dd424-2009-4eea-ff96-ae01e38e7ba3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5616, 3590,    3, ...,    0,    0,    1],\n",
              "       [4060,   21,    4, ...,    0,    0,    1],\n",
              "       [1125, 3273,    2, ...,    0,    0,    0],\n",
              "       ...,\n",
              "       [1100, 3525,    1, ...,    0,    0,    0],\n",
              "       [1971, 2355,    4, ...,    0,    1,    0],\n",
              "       [5136, 1429,    4, ...,    0,    0,    0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the Ranodom Search\n",
        "random_search = RandomizedSearchCV(estimator=RandomForestClassifier(),\n",
        "                                   param_distributions=param_dist, n_iter=15,\n",
        "                                   cv=inner_cv, scoring='accuracy',\n",
        "                                   random_state=42)\n",
        "\n",
        "# Define output lists\n",
        "outer_scores = []\n",
        "val_scores = []\n",
        "best_params_list = []\n",
        "\n",
        "# Perform nested cross-validation\n",
        "for train_idx, val_idx in outer_cv.split(X_train, y_train):\n",
        "    # Split the data into training and validation sets\n",
        "    X_train_fold = X_train.iloc[train_idx]\n",
        "    X_val_fold = X_train.iloc[val_idx]\n",
        "    y_train_fold = y_train.iloc[train_idx]\n",
        "    y_val_fold = y_train.iloc[val_idx]\n",
        "\n",
        "    # Fit the model on the training fold\n",
        "    random_search.fit(X_train_fold, y_train_fold)\n",
        "    best_model = random_search.best_estimator_\n",
        "\n",
        "    # Save the best parameters for this fold\n",
        "    best_params_list.append(random_search.best_params_)\n",
        "\n",
        "    # Evaluate on the validation set\n",
        "    val_predictions = best_model.predict(X_val_fold)\n",
        "    val_acc = accuracy_score(y_val_fold, val_predictions)\n",
        "    val_prec = precision_score(y_val_fold, val_predictions, average='weighted')\n",
        "    val_rec = recall_score(y_val_fold, val_predictions, average='weighted')\n",
        "    val_f1 = f1_score(y_val_fold, val_predictions, average='weighted')\n",
        "\n",
        "    # Append validation metrics\n",
        "    val_scores.append((val_acc, val_prec, val_rec, val_f1))\n",
        "\n",
        "    # Store the outer fold score (accuracy)\n",
        "    outer_scores.append(random_search.best_score_)\n",
        "\n",
        "# Print the performance of the nested cross-validation\n",
        "print(f\"Nested Cross-Validation Accuracy: {np.mean(outer_scores):.2f} ± {np.std(outer_scores):.2f}\")\n",
        "\n",
        "# Print validation set performance for each fold\n",
        "val_scores = np.array(val_scores)\n",
        "print(\"Validation Set Performance:\")\n",
        "print(f\"Accuracy: {val_scores[:, 0].mean():.2f} ± {val_scores[:, 0].std():.2f}\")\n",
        "print(f\"Precision: {val_scores[:, 1].mean():.2f} ± {val_scores[:, 1].std():.2f}\")\n",
        "print(f\"Recall: {val_scores[:, 2].mean():.2f} ± {val_scores[:, 2].std():.2f}\")\n",
        "print(f\"F1 Score: {val_scores[:, 3].mean():.2f} ± {val_scores[:, 3].std():.2f}\")\n",
        "\n",
        "# Print the best parameters found during hyperparameter tuning\n",
        "print(\"Best parameters found during hyperparameter tuning:\")\n",
        "for i, params in enumerate(best_params_list):\n",
        "    print(f\"Fold {i+1}: {params}\")\n",
        "\n",
        "# Fit the best model found on the entire training set\n",
        "random_search.fit(X_train, y_train)\n",
        "best_model = random_search.best_estimator_\n",
        "\n",
        "# Evaluate on the test set\n",
        "test_predictions = best_model.predict(X_test)\n",
        "print(\"Test Set Performance:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, test_predictions):.2f}\")\n",
        "print(f\"Precision: {precision_score(y_test, test_predictions, average='weighted'):.2f}\")\n",
        "print(f\"Recall: {recall_score(y_test, test_predictions, average='weighted'):.2f}\")\n",
        "print(f\"F1 Score: {f1_score(y_test, test_predictions, average='weighted'):.2f}\")\n",
        "\n",
        "# Print the best parameters of the best-performing model\n",
        "print(\"Best Parameters of the Best-Performing Model:\")\n",
        "print(random_search.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1DTIy_4l37E",
        "outputId": "8507ec8a-5965-48d7-ec71-a11e75fa4362"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nested Cross-Validation Accuracy: 0.41 ± 0.00\n",
            "Validation Set Performance:\n",
            "Accuracy: 0.42 ± 0.00\n",
            "Precision: 0.42 ± 0.00\n",
            "Recall: 0.42 ± 0.00\n",
            "F1 Score: 0.39 ± 0.00\n",
            "Best parameters found during hyperparameter tuning:\n",
            "Fold 1: {'n_estimators': 250, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_depth': 40}\n",
            "Fold 2: {'n_estimators': 300, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_depth': 30}\n",
            "Fold 3: {'n_estimators': 250, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_depth': 40}\n",
            "Fold 4: {'n_estimators': 300, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_depth': 30}\n",
            "Fold 5: {'n_estimators': 300, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_depth': 30}\n",
            "Test Set Performance:\n",
            "Accuracy: 0.42\n",
            "Precision: 0.43\n",
            "Recall: 0.42\n",
            "F1 Score: 0.40\n",
            "Best Parameters of the Best-Performing Model:\n",
            "{'n_estimators': 250, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_depth': 40}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gradient boosting, goede dataframe, goede code, nog runnen 15/11"
      ],
      "metadata": {
        "id": "7_Cagp6QC1Hy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "from google.colab import drive\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import KFold, RandomizedSearchCV\n",
        "from sklearn.model_selection import KFold, train_test_split, RandomizedSearchCV"
      ],
      "metadata": {
        "id": "3VrbWQDGC3Ex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load df Google Colab (feature engineered, encoded, scaled/unscaled)\n",
        "drive.mount('/content/drive')\n",
        "df_final = pd.read_csv(\"/content/drive/My Drive/Thesis/Data/df_final_2.csv\")\n",
        "\n",
        "df_final = df_final.astype(np.int32)"
      ],
      "metadata": {
        "id": "eAyttVcEDH3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define feature and target\n",
        "X = df_final.drop(columns=['Rating'])\n",
        "y = df_final['Rating']\n",
        "\n",
        "# Split data 80% train, 20% test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
        "                                                    stratify=y, random_state=42)\n",
        "# Define the parameter grid for tuning\n",
        "param_dist = {\n",
        "    'n_estimators': [50, 100, 150, 200],\n",
        "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
        "    'max_depth': [3, 7, 10, 20]\n",
        "}\n",
        "\n",
        "# Define the inner and outer cross-validation strategies\n",
        "inner_cv = KFold(n_splits=3, shuffle=True, random_state=42)\n",
        "outer_cv = KFold(n_splits=5, shuffle=True, random_state=42)"
      ],
      "metadata": {
        "id": "ZcQDUUK5DUn6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the RandomizedSearchCV\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=GradientBoostingClassifier(),\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=15,\n",
        "    cv=inner_cv,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1  # Utilize all available cores for parallel processing\n",
        ")\n",
        "\n",
        "# Define output lists\n",
        "outer_scores = []\n",
        "val_scores = []\n",
        "best_params_list = []\n",
        "\n",
        "# Perform nested CV\n",
        "for train_idx, val_idx in outer_cv.split(X_train, y_train):\n",
        "    # Split the data into training and validation sets\n",
        "    X_train_fold = X_train.iloc[train_idx]\n",
        "    X_val_fold = X_train.iloc[val_idx]\n",
        "    y_train_fold = y_train.iloc[train_idx]\n",
        "    y_val_fold = y_train.iloc[val_idx]\n",
        "\n",
        "    # Fit the model on the training fold\n",
        "    random_search.fit(X_train_fold, y_train_fold)\n",
        "    best_model = random_search.best_estimator_\n",
        "\n",
        "    # Save the best parameters for this fold\n",
        "    best_params_list.append(random_search.best_params_)\n",
        "\n",
        "    # Evaluate on the validation set\n",
        "    val_predictions = best_model.predict(X_val_fold)\n",
        "    val_acc = accuracy_score(y_val_fold, val_predictions)\n",
        "    val_prec = precision_score(y_val_fold, val_predictions, average='weighted')\n",
        "    val_rec = recall_score(y_val_fold, val_predictions, average='weighted')\n",
        "    val_f1 = f1_score(y_val_fold, val_predictions, average='weighted')\n",
        "\n",
        "    # Store validation metrics\n",
        "    val_scores.append((val_acc, val_prec, val_rec, val_f1))\n",
        "\n",
        "    # Store the outer fold score (accuracy)\n",
        "    outer_scores.append(random_search.best_score_)\n",
        "\n",
        "# Print the performance of the nested CV\n",
        "print(f\"Nested Cross-Validation Accuracy: {np.mean(outer_scores):.2f} ± {np.std(outer_scores):.2f}\")\n",
        "\n",
        "# Print validation set performance for each fold\n",
        "val_scores = np.array(val_scores)\n",
        "print(\"Validation Set Performance:\")\n",
        "print(f\"Accuracy: {val_scores[:, 0].mean():.2f} ± {val_scores[:, 0].std():.2f}\")\n",
        "print(f\"Precision: {val_scores[:, 1].mean():.2f} ± {val_scores[:, 1].std():.2f}\")\n",
        "print(f\"Recall: {val_scores[:, 2].mean():.2f} ± {val_scores[:, 2].std():.2f}\")\n",
        "print(f\"F1 Score: {val_scores[:, 3].mean():.2f} ± {val_scores[:, 3].std():.2f}\")\n",
        "\n",
        "# Print the best parameters found during hyperparameter tuning\n",
        "print(\"Best parameters found during hyperparameter tuning:\")\n",
        "for i, params in enumerate(best_params_list):\n",
        "    print(f\"Fold {i+1}: {params}\")\n",
        "\n",
        "# Define the best parameters found in nested CV\n",
        "best_params = best_params_list[np.argmax(outer_scores)]\n",
        "\n",
        "# Train best model\n",
        "best_model = GradientBoostingClassifier(**best_params, random_state=42)\n",
        "best_model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate on the test set\n",
        "test_predictions = best_model.predict(X_test)\n",
        "print(\"Test set performance for best performing model:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, test_predictions):.2f}\")\n",
        "print(f\"Precision: {precision_score(y_test, test_predictions, average='weighted'):.2f}\")\n",
        "print(f\"Recall: {recall_score(y_test, test_predictions, average='weighted'):.2f}\")\n",
        "print(f\"F1 Score: {f1_score(y_test, test_predictions, average='weighted'):.2f}\")\n",
        "\n",
        "# Print the parameters for the best-performing model\n",
        "print(\"Parameters for the best performing model:\")\n",
        "print(best_params)\n",
        "\n",
        "# Save the best performing model\n",
        "joblib_file = \"/content/drive/My Drive/Thesis/Models/Baseline_GB.pkl\"\n",
        "joblib.dump(best_model, joblib_file)"
      ],
      "metadata": {
        "id": "xh2Q3j-eDw1z"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V28"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}